{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Hedging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at implementing Deep Hedging to showcase the effect of transaction costs on the hedging and pricing of an option, the easiest way possible for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we simulate paths of an asset following a Geometric Brownian Motion, we define a portfolio consisting of shares in this asset and a short position in a call option and we try to maximize the expected utility of the termianl wealth in the portfolio, by controling the number of shares in the portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep hedging, the control is chosen by a neural network policy which will be trained by Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gamma = 0.1 # Risk aversion parameter\n",
    "lambda_tc = 0.000001 # Proportional transaction costs \n",
    "# --- Underlying parameters ---\n",
    "S0 = 100\n",
    "mu = 0.05\n",
    "sigma = 0.2\n",
    "# -----------------------------\n",
    "# --- Option parameters ---\n",
    "T = 1.0\n",
    "strike = 100\n",
    "N_steps = 30\n",
    "# -------------------------\n",
    "# --- Policy parameters ---\n",
    "clip_trade = 2.0\n",
    "clip_pos = 10.0\n",
    "batch_size = 64\n",
    "epochs = 3000\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Underlying path simulation\n",
    "# ---------------------------------------------------------\n",
    "def simulate_gbm(S0, mu, sigma, T, N_steps, batch_size):\n",
    "    dt = T / N_steps\n",
    "    S = np.full((batch_size, N_steps+1), S0)\n",
    "    for t in range(1, N_steps+1):\n",
    "        z = np.random.randn(batch_size)\n",
    "        S[:, t] = S[:, t-1] * np.exp((mu - 0.5 * sigma**2)*dt + sigma*np.sqrt(dt)*z)\n",
    "    return S  # shape: [batch_size, N_steps+1]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Utility function\n",
    "# ---------------------------------------------------------\n",
    "def cara_utility(w, gamma):\n",
    "    exp_arg = torch.clamp(-gamma * w, min=-100, max=100)\n",
    "    utility = - torch.exp(exp_arg)\n",
    "    return utility\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# BS Delta for initialization\n",
    "# ---------------------------------------------------------\n",
    "def bs_call_delta(S, K, sigma, T, t):\n",
    "    tau = T - t\n",
    "    if tau <= 0:\n",
    "        return (S > K).astype(float)\n",
    "    d1 = (np.log(S / K) + 0.5 * sigma**2 * tau) / (sigma * np.sqrt(tau))\n",
    "    return norm.cdf(d1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Computation of the terminal wealth for a path and policy \n",
    "# ---------------------------------------------------------\n",
    "def compute_terminal_wealth(S_path, trades, strike, lambda_tc):\n",
    "    y = 0\n",
    "    cash = 0\n",
    "    for t in range(len(trades)):\n",
    "        d_y = trades[t]\n",
    "        price = S_path[t]\n",
    "        cost = lambda_tc * abs(d_y) * price\n",
    "        cash -= d_y * price + cost\n",
    "        y += d_y\n",
    "    # At expiry\n",
    "    S_T = S_path[-1]\n",
    "    # Liquidate\n",
    "    cash += y * S_T - lambda_tc * abs(y) * S_T\n",
    "    # Payoff (short call)\n",
    "    payoff = max(S_T - strike, 0)\n",
    "    return cash - payoff\n",
    "\n",
    "def compute_terminal_wealth_no_option(S_path, trades, lambda_tc):\n",
    "    y = 0\n",
    "    cash = 0\n",
    "    for t in range(len(trades)):\n",
    "        d_y = trades[t]\n",
    "        price = S_path[t]\n",
    "        cost = lambda_tc * abs(d_y) * price\n",
    "        cash -= d_y * price + cost\n",
    "        y += d_y\n",
    "    # At expiry\n",
    "    S_T = S_path[-1]\n",
    "    # Liquidate \n",
    "    cash += y * S_T - lambda_tc * abs(y) * S_T\n",
    "    return cash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Policy Neural Network : A simple Feed Forward Network\n",
    "# ---------------------------------------------------------\n",
    "class SimplePolicyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Training function, takes option as input, to be able to train with and without the option\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "def train(policy, optimizer, epochs, option=True):\n",
    "    utility_history = []\n",
    "    wealth_history = []\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        # Simulate batch of paths\n",
    "        S_paths = simulate_gbm(S0, mu, sigma, T, N_steps, batch_size)\n",
    "        S_paths = torch.tensor(S_paths, dtype=torch.float32)\n",
    "\n",
    "        y = torch.zeros(batch_size)\n",
    "        trades = []\n",
    "        for t in range(N_steps):\n",
    "            price = S_paths[:, t]\n",
    "            time_feat = torch.full((batch_size, 1), t/N_steps)\n",
    "            y_feat = y.unsqueeze(1)\n",
    "            x = torch.cat([price.unsqueeze(1)/S0, time_feat, y_feat], dim=1)\n",
    "            d_y = policy(x).squeeze(1)\n",
    "            d_y = torch.clamp(d_y, -clip_trade, clip_trade)\n",
    "            trades.append(d_y)\n",
    "            y = torch.clamp(y + d_y, -clip_pos, clip_pos)\n",
    "\n",
    "        cash = torch.zeros(batch_size)\n",
    "        y = torch.zeros(batch_size)\n",
    "        for t in range(N_steps):\n",
    "            d_y = trades[t]\n",
    "            price = S_paths[:, t]\n",
    "            cost = lambda_tc * torch.abs(d_y) * price\n",
    "            cash = cash - d_y * price - cost\n",
    "            y = torch.clamp(y + d_y, -clip_pos, clip_pos)\n",
    "        S_T = S_paths[:, -1]\n",
    "        cash = cash + y * S_T - lambda_tc * torch.abs(y) * S_T\n",
    "        payoff = torch.relu(S_T - strike)\n",
    "        if option:\n",
    "            terminal_wealth = cash - payoff\n",
    "        else:\n",
    "            terminal_wealth = cash\n",
    "        terminal_wealth = torch.clamp(terminal_wealth, min=-200, max=200)\n",
    "        utility = - torch.exp(-gamma * terminal_wealth)\n",
    "        loss = -utility.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        utility_history.append(utility.mean().item())\n",
    "        wealth_history.append(terminal_wealth.mean().item())\n",
    "        loss_history.append(loss.item())\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: loss = {loss:.4f}, mean terminal wealth = {terminal_wealth.mean().item():.2f}\")\n",
    "\n",
    "    plt.plot(loss_history)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(f'Loss (-E(U)), with option = {option}')\n",
    "    plt.show()\n",
    "    return utility_history, wealth_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we first train the two models to align with BS delta hedging or to do nothing (no option case), so there isn't problems regarding initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Initialization loss = 0.466556\n",
      "Epoch 100: Initialization loss = 0.021579\n",
      "Epoch 0: Zero initialization loss = 0.029619\n",
      "Epoch 100: Zero initialization loss = 0.000003\n"
     ]
    }
   ],
   "source": [
    "S_grid = np.linspace(0.5*S0, 1.5*S0, 100)\n",
    "t_grid = np.linspace(0, T, N_steps+1)\n",
    "y_grid = np.array([0.0])  # Usually zero initial hedge\n",
    "\n",
    "inputs = []\n",
    "deltas = []\n",
    "\n",
    "for t in t_grid:\n",
    "    for S in S_grid:\n",
    "        delta = bs_call_delta(S, strike, sigma, T, t)\n",
    "        inputs.append([S/S0, t/T, 0.0])  # Normalized inputs as used in your NN\n",
    "        deltas.append(delta)\n",
    "        \n",
    "inputs_tensor = torch.tensor(inputs, dtype=torch.float32)\n",
    "deltas_tensor = torch.tensor(deltas, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "policy = SimplePolicyNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)\n",
    "\n",
    "# Short supervised training (initialization only)\n",
    "epochs_init = 200  # short training to approximate delta\n",
    "\n",
    "for epoch in range(epochs_init):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = policy(inputs_tensor)\n",
    "    loss = criterion(outputs, deltas_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Initialization loss = {loss.item():.6f}\")\n",
    "\n",
    "\n",
    "inputs_zero = inputs_tensor\n",
    "outputs_zero = torch.zeros_like(deltas_tensor)\n",
    "\n",
    "policy_no_option = SimplePolicyNet()\n",
    "optimizer_no_option = torch.optim.Adam(policy_no_option.parameters(), lr=1e-3)\n",
    "\n",
    "epochs_init_zero = 200\n",
    "\n",
    "for epoch in range(epochs_init_zero):\n",
    "    optimizer_no_option.zero_grad()\n",
    "    outputs = policy_no_option(inputs_zero)\n",
    "    loss = criterion(outputs, outputs_zero)\n",
    "    loss.backward()\n",
    "    optimizer_no_option.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Zero initialization loss = {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 485165120.0000, mean terminal wealth = -200.00\n",
      "Epoch 100: loss = 485165120.0000, mean terminal wealth = -200.00\n",
      "Epoch 200: loss = 485165120.0000, mean terminal wealth = -200.00\n",
      "Epoch 300: loss = 485165120.0000, mean terminal wealth = -200.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m policy = policy\n\u001b[32m      6\u001b[39m optimizer = torch.optim.Adam(policy.parameters(), lr=\u001b[32m1e-5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m utility_with, wealth_with = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m policy_no_option = policy_no_option\n\u001b[32m     10\u001b[39m optimizer_without = torch.optim.Adam(policy_no_option.parameters(), lr=\u001b[32m1e-5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(policy, optimizer, epochs, option)\u001b[39m\n\u001b[32m     20\u001b[39m y_feat = y.unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m     21\u001b[39m x = torch.cat([price.unsqueeze(\u001b[32m1\u001b[39m)/S0, time_feat, y_feat], dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m d_y = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m d_y = torch.clamp(d_y, -clip_trade, clip_trade)\n\u001b[32m     24\u001b[39m trades.append(d_y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mSimplePolicyNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1507\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1504\u001b[39m             tracing_state.pop_scope()\n\u001b[32m   1505\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1508\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1509\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Training \n",
    "# ---------------------------------------------------------\n",
    "\n",
    "policy = policy\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-5)\n",
    "utility_with, wealth_with = train(policy, optimizer, epochs=epochs, option=True)\n",
    "\n",
    "policy_no_option = policy_no_option\n",
    "optimizer_without = torch.optim.Adam(policy_no_option.parameters(), lr=1e-5)\n",
    "utility_without, wealth_without = train(policy_no_option, optimizer, epochs, option=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wealth_with[epochs-1000:], bins=100)\n",
    "plt.title(\"Distribution of Terminal Wealth (last 1000 epochs)\")\n",
    "plt.xlabel(\"Terminal Wealth\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Evaluate function, to run simulations with the trained policy\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def evaluate(policy, n_paths=10000, option=True):\n",
    "    policy.eval()  # set policy to evaluation mode (good practice)\n",
    "    with torch.no_grad():\n",
    "        S_paths = simulate_gbm(S0, mu, sigma, T, N_steps, n_paths)\n",
    "        S_paths = torch.tensor(S_paths, dtype=torch.float32)\n",
    "\n",
    "        y = torch.zeros(n_paths)\n",
    "        trades = []\n",
    "        for t in range(N_steps):\n",
    "            price = S_paths[:, t]\n",
    "            time_feat = torch.full((n_paths, 1), t/N_steps)\n",
    "            y_feat = y.unsqueeze(1)\n",
    "            x = torch.cat([price.unsqueeze(1)/S0, time_feat, y_feat], dim=1)\n",
    "            d_y = policy(x).squeeze(1)\n",
    "            d_y = torch.clamp(d_y, -clip_trade, clip_trade)\n",
    "            trades.append(d_y)\n",
    "            y = torch.clamp(y + d_y, -clip_pos, clip_pos)\n",
    "\n",
    "        cash = torch.zeros(n_paths)\n",
    "        y = torch.zeros(n_paths)\n",
    "        for t in range(N_steps):\n",
    "            d_y = trades[t]\n",
    "            price = S_paths[:, t]\n",
    "            cost = lambda_tc * torch.abs(d_y) * price\n",
    "            cash = cash - d_y * price - cost\n",
    "            y = torch.clamp(y + d_y, -clip_pos, clip_pos)\n",
    "        S_T = S_paths[:, -1]\n",
    "        cash = cash + y * S_T - lambda_tc * torch.abs(y) * S_T\n",
    "        payoff = torch.relu(S_T - strike)\n",
    "        if option:\n",
    "            terminal_wealth = cash - payoff\n",
    "        else:\n",
    "            terminal_wealth = cash\n",
    "        terminal_wealth = torch.clamp(terminal_wealth, min=-1e3, max=1e3)\n",
    "        utility = - torch.exp(-gamma * terminal_wealth)\n",
    "        # Return full batch for statistical estimation\n",
    "        return terminal_wealth.numpy(), utility.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility indifference price: -64.9750\n"
     ]
    }
   ],
   "source": [
    "# Evaluate expected exp(-gamma * terminal_wealth) for both cases\n",
    "\n",
    "def expected_exp_utility(policy, option=True, n_paths=10000):\n",
    "    policy.eval()\n",
    "    with torch.no_grad():\n",
    "        S_paths = simulate_gbm(S0, mu, sigma, T, N_steps, n_paths)\n",
    "        S_paths = torch.tensor(S_paths, dtype=torch.float32)\n",
    "\n",
    "        y = torch.zeros(n_paths)\n",
    "        trades = []\n",
    "        for t in range(N_steps):\n",
    "            price = S_paths[:, t]\n",
    "            time_feat = torch.full((n_paths, 1), t/N_steps)\n",
    "            y_feat = y.unsqueeze(1)\n",
    "            x = torch.cat([price.unsqueeze(1)/S0, time_feat, y_feat], dim=1)\n",
    "            d_y = policy(x).squeeze(1)\n",
    "            d_y = torch.clamp(d_y, -clip_trade, clip_trade)\n",
    "            trades.append(d_y)\n",
    "            y = torch.clamp(y + d_y, -clip_pos, clip_pos)\n",
    "        cash = torch.zeros(n_paths)\n",
    "        y = torch.zeros(n_paths)\n",
    "        for t in range(N_steps):\n",
    "            d_y = trades[t]\n",
    "            price = S_paths[:, t]\n",
    "            cost = lambda_tc * torch.abs(d_y) * price\n",
    "            cash = cash - d_y * price - cost\n",
    "            y = torch.clamp(y + d_y, -clip_pos, clip_pos)\n",
    "        S_T = S_paths[:, -1]\n",
    "        cash = cash + y * S_T - lambda_tc * torch.abs(y) * S_T\n",
    "        payoff = torch.relu(S_T - strike)\n",
    "        if option:\n",
    "            terminal_wealth = cash - payoff\n",
    "        else:\n",
    "            terminal_wealth = cash\n",
    "        # Don't clamp too aggressively here!\n",
    "        exp_util = torch.exp(-gamma * terminal_wealth)\n",
    "        return exp_util.mean().item()\n",
    "\n",
    "# After training both policies\n",
    "V_H = expected_exp_utility(policy, option=True, n_paths=10000)\n",
    "V_0 = expected_exp_utility(policy_no_option, option=False, n_paths=10000)\n",
    "\n",
    "p_star = (1/gamma) * np.log(V_0 / V_H)\n",
    "print(f\"Utility indifference price: {p_star:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
